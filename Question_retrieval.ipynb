{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on https://arxiv.org/pdf/1707.05409.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil_chuykin/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/home/daniil_chuykin/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404287, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_len = train_data[train_data['is_duplicate'] == 1].shape[0]\n",
    "second_len = train_data[train_data['is_duplicate'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEICAYAAACJalkVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHyZJREFUeJzt3X24VXWd9/H3Rx7E0lRAHOGQYDJNakqG5tyWmU6KlKDeeY1Ok6gUXY10210zieUESo52l5lOZelIYBnkWAo5qJGpTQ8+oJkI1nBSkgOECD6g5gP4vf9Yv5PLwz57rwOsszbbz+u61rXX+q6n79ro/p71W7+1liICMzOzMu1QdQJmZtb6XGzMzKx0LjZmZlY6FxszMyudi42ZmZXOxcbMzErnYmO2FSQtkXRkL+9Tkr4j6UlJ9/TmvrclSSFp36rzsN7Rt+oEzPIkLQf2BDYBzwELgE9GxLNV5gUgaRbQERHndcYiYv8KUnk38H6gLSKeq2D/Zj3mMxtrRsdHxM7AwcAhwHldF0h/3ffaf7+S+vTWvgrYG1juQmPbExcba1oRsRK4GTgAQNIdki6U9EvgeWAfSUMlzZe0XlK7pI91ri9puqTrJf1A0gZJ90s6KDf/bWmbT6XmsPG5ebMkXSFpgaTngEnAh4HPSnpW0o/Tcssl/V0a31HS1yStSsPXJO2Y5h0pqUPSZyQ9Lmm1pDO6O/bujkvSJOA/gL9NeZzfzfpnSno4NbXdKmnvFP9fkp6QNDxNH5SO/2/S9FRJf0jf11JJJ+a2ebqkX0q6NK3zSNre6ZJWpOOa2OU7/JakhWl7d3bmUSPfHSV9RdJjktak9XZK8wZLuintc72k/+7NPzRsG4kIDx6aZgCWA3+XxocDS4AZafoO4DFgf7Im4H7AncA3gQHAaGAtcHRafjrwMvChtOw/A4+m8X5AO/A5oD9wFLABeGtadxbwNHA42R9lA1Lsi3XyvQC4CxgC7AH8Kpf7kcDGtEw/YBxZwdy9m++h3nGdDvyiznd4Qjq2t6Xv6TzgV7n5FwI/A3YCHgSm5OadDAxNx/z3ZE2Ze+X2uxE4A+gDfDH9e3wD2BE4Jn2HO+e+ww3AEWn+Zfm8gQD2TeNfA+YDA4FdgB8DF6V5FwHfyv27vQdQ1f+teujh/9tVJ+DBQ35IP97PAk8Bf0w/uDuleXcAF+SWHU52bWeXXOwiYFYanw7clZu3A7A6/Vi9B/gTsENu/hxgehqfBVzTJbdZ1C82fwDG5eYdS9bcBVmx+TPQNzf/ceCwGt9Bo+NqVGxuBiZ1Oe7ngb3TdD/gPmAxcEu9H27gAWBCbr/LcvPengrGnrnYOmB07vuam5u3czqu4Wk6gH0BkRW1t+SW/Vvg0TR+ATCPVJg8bJ+DT0WtGZ0QEbtFxN4R8U8R8efcvBW58aHA+ojYkIv9ERhWa/mIeAXoSOsNBVakWMN1CxqatpHf3tDc9LqI2Jibfp7sB7jWdhodVz17A5elZqengPVkP+jDACLiZbJCcABwSaRfdABJp0l6ILfuAcDg3LbX5Mb/nLbXNZY/pvz3/2zKJf+dQHYW+Abgvtx+b0lxgC+Tnan9JDXdTS34PVgTcbGx7U3+MeWrgIGSdsnF3gyszE0P7xxJ7fxtab1VwPAubf9d1+36SPRGj0hfRfZDn9/eqgbrdLedRsdVzwrg46lgdw47RcSvACQNA6YB3wEuyV1X2hu4CpgCDIqI3YCHyArVlsp//zuTNZN1/U6eICtS++fy3TWyTiJExIaI+ExE7AMcD3xa0tFbkZNVwMXGtlsRsYLsushFkgZIOpDsQv61ucXeKekkSX2BTwEvkl1XuZus6eazkvopu1fmeGBunV2uAfapM38OcJ6kPSQNBr4AfK+k46rnW8C5kvYHkLSrpJPTuMjOaq5O21wNzEjrvZGsoK5Ny55B6pyxFcZJerek/mk/d6fj+4t0dnkVcKmkIWnfwyQdm8Y/KGnflPszZE1xm7YyL+tlLja2vTsVGEH21/INwLSIWJibP4/sQveTwEeAkyLi5Yh4CRgPHEf2l/U3gdMi4nd19nU1sF9q6rmxxvwvAovILrovBu5PsTKOq1sRcQPwJWCupGfIzk6OS7P/D9l9TP+ams/OAM6Q9J6IWApcAvyarLC+HfjlFubf6ftkZ1HrgXeS9eir5RyyprK7Us4/Bd6a5o1K08+m3L4ZEXdsZV7Wy5RrrjVrKZKmk11U/seqc3k9Uo2bYO31y2c2ZmZWOhcbMzMrnZvRzMysdD6zMTOz0vmpz8ngwYNjxIgRVadhZrZdue+++56IiD0aLedik4wYMYJFixZVnYaZ2XZF0h8bL+VmNDMz6wUuNmZmVjoXGzMzK52v2dTx8ssv09HRwQsvvFB1Kt0aMGAAbW1t9OvXr+pUzMy65WJTR0dHB7vssgsjRowgewZgc4kI1q1bR0dHByNHjqw6HTOzbrkZrY4XXniBQYMGNWWhAZDEoEGDmvrMy8wMXGwaatZC06nZ8zMzAxcbMzPrBb5m0wMjpv7XNt3e8os/0HCZM888k5tuuokhQ4bw0EMPbdP9m5n1FhebJnf66aczZcoUTjvttKpTMXut6btWnYFtK9OfLn0XpTWjSRou6XZJD0taIunsFJ8uaaWkB9IwLrfOuZLaJf2+85WwKT42xdolTc3FR0q6W9IyST9Ir55F0o5puj3NH1HWcZbtiCOOYODAgVWnYWa2Vcq8ZrMR+ExEvA04DDhL0n5p3qURMToNCwDSvFOA/YGxwDcl9ZHUB/gG2Wtt9wNOzW3nS2lbo8he+zspxScBT0bEvsClaTkzM6tIacUmIlZHxP1pfAPwMDCszioTgLkR8WJEPEr2PvJD09AeEY+k98bPBSYo64Z1FHB9Wn82cEJuW7PT+PXA0XK3LTOzyvRKb7TUjPUO4O4UmiLpQUkzJe2eYsOAFbnVOlKsu/gg4KmI2Ngl/pptpflPp+W75jVZ0iJJi9auXbtVx2hmZt0rvdhI2hn4IfCpiHgGuAJ4CzAaWA1c0rlojdVjC+L1tvXaQMSVETEmIsbssUfD1zGYmdkWKrU3mqR+ZIXm2oj4EUBErMnNvwq4KU12AMNzq7cBq9J4rfgTwG6S+qazl/zyndvqkNQX2BVYv7XHU6Sr8rZ26qmncscdd/DEE0/Q1tbG+eefz6RJkxqvaGbWREorNukaydXAwxHx1Vx8r4hYnSZPBDpvHpkPfF/SV4GhwCjgHrKzlFGSRgIryToR/ENEhKTbgQ+RXceZCMzLbWsi8Os0/2cRsdmZzfZgzpw5VadgZrbVyjyzORz4CLBY0gMp9jmy3mSjyZq1lgMfB4iIJZKuA5aS9WQ7KyI2AUiaAtwK9AFmRsSStL1zgLmSvgj8hqy4kT6/K6md7IzmlBKP08zMGiit2ETEL6h97WRBnXUuBC6sEV9Qa72IeISst1rX+AvAyT3J18zMyuNno5mZWelcbMzMrHQuNmZmVjoXGzMzK52f+twT2/optwWftHrLLbdw9tlns2nTJj760Y8yderUxiuZmTURn9k0uU2bNnHWWWdx8803s3TpUubMmcPSpUurTsvMrEdcbJrcPffcw7777ss+++xD//79OeWUU5g3b17jFc3MmoiLTZNbuXIlw4e/+rSetrY2Vq5cWWFGZmY952LT5Go9ZcdvSzCz7Y2LTZNra2tjxYpX37DQ0dHB0KFDK8zIzKznXGya3CGHHMKyZct49NFHeemll5g7dy7jx4+vOi0zsx5x1+eeKNhVeVvq27cvX//61zn22GPZtGkTZ555Jvvvv3+v52FmtjVcbLYD48aNY9y4cVWnYWa2xdyMZmZmpXOxMTOz0rnYNNDsL/hs9vzMzMDFpq4BAwawbt26pv1BjwjWrVvHgAEDqk7FzKwudxCoo62tjY6ODtauXVt1Kt0aMGAAbW1tVadhZlaXi00d/fr1Y+TIkVWnYWa23XMzmpmZlc7FxszMSudiY2ZmpXOxMTOz0rnYmJlZ6VxszMysdC42ZmZWOhcbMzMrnYuNmZmVzsXGzMxK52JjZmalc7ExM7PSlVZsJA2XdLukhyUtkXR2ig+UtFDSsvS5e4pL0uWS2iU9KOng3LYmpuWXSZqYi79T0uK0zuWSVG8fZmZWjTLPbDYCn4mItwGHAWdJ2g+YCtwWEaOA29I0wHHAqDRMBq6ArHAA04B3AYcC03LF44q0bOd6Y1O8u32YmVkFSis2EbE6Iu5P4xuAh4FhwARgdlpsNnBCGp8AXBOZu4DdJO0FHAssjIj1EfEksBAYm+a9KSJ+Hdnbza7psq1a+zAzswr0yjUbSSOAdwB3A3tGxGrIChIwJC02DFiRW60jxerFO2rEqbOPrnlNlrRI0qJmfkGamdn2rvRiI2ln4IfApyLimXqL1ojFFsQLi4grI2JMRIzZY489erKqmZn1QKnFRlI/skJzbUT8KIXXpCYw0ufjKd4BDM+t3gasahBvqxGvtw8zM6tAmb3RBFwNPBwRX83Nmg909iibCMzLxU9LvdIOA55OTWC3AsdI2j11DDgGuDXN2yDpsLSv07psq9Y+zMysAn0bLSDpcOCBiHhO0j8CBwOXRcQfG6x6OPARYLGkB1Lsc8DFwHWSJgGPASeneQuAcUA78DxwBkBErJc0A7g3LXdBRKxP458AZgE7ATengTr7MDOzCijryFVnAelB4CDgQOC7ZGcrJ0XEe8tPr/eMGTMmFi1aVHUaZtuP6btWnYFtK9Of3uJVJd0XEWMaLVekGW1j6lo8geyM5jJgly3OzMzMXncaNqORXRc5l6xJ7D2S+gD9yk3LzMxaSZEzm78HXgTOjIg/kd3L8uVSszIzs5bSsNikAvNDYMcUegK4ocykzMystTQsNpI+BlwPfDuFhgE3lpmUmZm1liLNaGeRdWN+BiAiltHN41/MzMxqKVJsXoyIlzonJPWlh4+FMTOz17cixeZOSZ8DdpL0fuA/gR+Xm5aZmbWSIsVmKrAWWAx8nOxO//PKTMrMzFpLw/tsIuIV4Ko0mJmZ9Vi3xUbSYupcm4mIA0vJyMzMWk69M5sP9loWZmbW0rotNvmnOkv6K+BQsjOde9ONnmZmZoUUuanzo8A9wEnAh4C7JJ1ZdmJmZtY6ijyI81+Ad0TEOgBJg4BfATPLTMzMzFpHka7PHcCG3PQGYEU56ZiZWSsqcmazErhb0jyyazYTgHskfRqgyyufzczMNlOk2PwhDZ3mpU+/QM3MzAopclPn+b2RiJmZta6GxUbSGODzwN755X1Tp5mZFVWkGe1ash5pi4FXyk3HzMxaUZFiszYi5peeiZmZtawixWaapP8AbgNe7AxGxI9Ky8rMzFpKkWJzBvA3QD9ebUYLwMXGzMwKKVJsDoqIt5eeiZmZtawiTxC4S9J+pWdiZmYtq8iZzbuBiZIeJbtmIyDc9dnMzIoqUmzGlp6FmZm1tCJPEPgjgKQhwIDSMzIzs5ZT5H024yUtAx4F7gSWAzeXnJeZmbWQIh0EZgCHAf8TESOBo4FflpqVmZm1lCLF5uX04rQdJO0QEbcDo0vOy8zMWkiRYvOUpJ2BnwPXSroM2NhoJUkzJT0u6aFcbLqklZIeSMO43LxzJbVL+r2kY3PxsSnWLmlqLj5S0t2Slkn6gaT+Kb5jmm5P80cU+SLMzKw8RYrNBODPwP8FbiF7t83xBdabRe2ebJdGxOg0LABI9/GcAuyf1vmmpD6S+gDfAI4D9gNOzd3z86W0rVHAk8CkFJ8EPBkR+wKXpuXMzKxCRYrN3hGxKSI2RsTsiLgcaPhEgYj4ObC+YB4TgLkR8WJEPAq0A4emoT0iHomIl4C5wARJAo4Crk/rzwZOyG1rdhq/Hjg6LW9mZhUpUmyuk3SOMjtJ+nfgoq3Y5xRJD6Zmtt1TbBiwIrdMR4p1Fx8EPBURG7vEX7OtNP/ptPxmJE2WtEjSorVr127FIZmZWT1Fbup8F1lT1K/IXgV9LXD4Fu7vCrLebZE+LwHOJHsqQVdB7WIYdZanwbzXBiOuBK4EGDNmTM1lihgx9b+2dFVrIssv/kDVKZi1rEK90ciu2exEdlPnoxGxRS9Ri4g1qUnuFeAqsmYyyM5MhucWbQNW1Yk/AewmqW+X+Gu2lebvSvHmPDMzK0GRYnMvWbE5hOw5aadKur7+KrVJ2is3eSLQ2VNtPnBK6kk2EhgF3JP2PSr1POtP1olgfkQEcDvwobT+RGBeblsT0/iHgJ+l5c3MrCJFmtEmRcSiNP4nsgv0H2m0kqQ5wJHAYEkdwDTgSEmjyZq1lgMfB4iIJZKuA5aSdas+KyI2pe1MAW4F+gAzI2JJ2sU5wFxJXwR+A1yd4lcD35XUTnZGc0qBYzQzsxIVeTbaIknvBkZFxHckDQZ+UWC9U2uEr64R61z+QuDCGvEFwIIa8Ud4tRkuH38BOLlRfmZm1nuKPBttGtlZxLkp1B/4XplJmZlZaylyzeZEYDzwHEBErCLrlWZmZlZIkWLzUrrAHgCS3lhuSmZm1mqK3tT5bbKuxh8DfkrWbdnMzKyQIh0EviLp/cAzwFuBL0TEwtIzMzOzllGk6zOpuLjAmJnZFinSjGZmZrZVXGzMzKx03RYbSbelT78PxszMtkq9azZ7SXovMF7SXLo8TTki7i81MzMzaxn1is0XgKlkT1T+apd5QfbyMjMzs4a6LTYRcT1wvaR/jYgZvZiTmZm1mCL32cyQNB44IoXuiIibyk3LzMxaSZEHcV4EnE32+P+lwNkpZmZmVkiRmzo/AIzufDunpNlk7485t+5aZmZmSdH7bHbLje9aRiJmZta6ipzZXAT8RtLtZN2fj8BnNWZm1gNFOgjMkXQHcAhZsTknIv5UdmJmZtY6ij6IczUwv+RczMysRfnZaGZmVjoXGzMzK13dYiNpB0kP9VYyZmbWmuoWm3RvzW8lvbmX8jEzsxZUpIPAXsASSfcAz3UGI2J8aVmZmVlLKVJszi89CzMza2lF7rO5U9LewKiI+KmkNwB9yk/NzMxaRZEHcX4MuB74dgoNA24sMykzM2stRbo+nwUcDjwDEBHLgCFlJmVmZq2lSLF5MSJe6pyQ1JfsTZ1mZmaFFCk2d0r6HLCTpPcD/wn8uNy0zMyslRQpNlOBtcBi4OPAAuC8MpMyM7PW0rDYpBs7ZwMzyLpBz46Ihs1okmZKejz/BAJJAyUtlLQsfe6e4pJ0uaR2SQ9KOji3zsS0/DJJE3Pxd0panNa5XJLq7cPMzKpTpDfaB4A/AJcDXwfaJR1XYNuzgLFdYlOB2yJiFHBbmgY4DhiVhsnAFWnfA4FpwLuAQ4FpueJxRVq2c72xDfZhZmYVKdKMdgnwvog4MiLeC7wPuLTRShHxc2B9l/AEsrMk0ucJufg1kbkL2E3SXsCxwMKIWB8RTwILgbFp3psi4tfpLOuaLtuqtQ8zM6tIkWLzeES056YfAR7fwv3tmd6N0/mOnM4u1MOAFbnlOlKsXryjRrzePszMrCLdPkFA0klpdImkBcB1ZF2eTwbu3cZ5qEYstiDes51Kk8ma4njzm/2sUTOzstQ7szk+DQOANcB7gSPJeqZt6UX3NakJjPTZeYbUAQzPLdcGrGoQb6sRr7ePzUTElRExJiLG7LHHHlt4SGZm1ki3ZzYRcUYJ+5sPTAQuTp/zcvEpkuaSdQZ4OiJWS7oV+Ldcp4BjgHMjYr2kDZIOA+4GTgP+vcE+zMysIg0fxClpJPBJYER++UavGJA0h+xMaLCkDrJeZRcD10maBDxG1iQH2b0744B24HngjLSP9ZJm8Gqz3QUR0dnp4BNkPd52Am5OA3X2YWZmFSnyioEbgavJnhrwStENR8Sp3cw6usayQfYMtlrbmQnMrBFfBBxQI76u1j7MzKw6RYrNCxFxeemZmJlZyypSbC6TNA34CfBiZzAi7i8tKzMzaylFis3bgY8AR/FqM1qkaTMzs4aKFJsTgX3yrxkwMzPriSJPEPgtsFvZiZiZWesqcmazJ/A7Sffy2ms2dbs+m5mZdSpSbKaVnoWZmbW0hsUmIu7sjUTMzKx1FXmCwAZefchlf6Af8FxEvKnMxMzMrHUUObPZJT8t6QSyF5mZmZkVUqQ32mtExI34HhszM+uBIs1oJ+UmdwDGsAXvjjEzs9evIr3Rjs+NbwSWk7162czMrJAi12zKeK+NmZm9jtR7LfQX6qwXETGjhHzMzKwF1Tuzea5G7I3AJGAQ4GJjZmaF1Hst9CWd45J2Ac4me4PmXOCS7tYzMzPrqu41G0kDgU8DHwZmAwdHxJO9kZiZmbWOetdsvgycBFwJvD0inu21rMzMrKXUu6nzM8BQ4DxglaRn0rBB0jO9k56ZmbWCetdsevx0ATMzs1pcUMzMrHQuNmZmVjoXGzMzK52LjZmZlc7FxszMSudiY2ZmpXOxMTOz0rnYmJlZ6VxszMysdC42ZmZWOhcbMzMrXSXFRtJySYslPSBpUYoNlLRQ0rL0uXuKS9LlktolPSjp4Nx2Jqbll0mamIu/M22/Pa2r3j9KMzPrVOWZzfsiYnREjEnTU4HbImIUcFuaBjgOGJWGycAV8Jd37UwD3gUcCkzrLFBpmcm59caWfzhmZtadZmpGm0D2gjbS5wm5+DWRuQvYTdJewLHAwohYn17othAYm+a9KSJ+HREBXJPblpmZVaCqYhPATyTdJ2lyiu0ZEasB0ueQFB8GrMit25Fi9eIdNeKbkTRZ0iJJi9auXbuVh2RmZt2p+1roEh0eEaskDQEWSvpdnWVrXW+JLYhvHoy4kuxNpIwZM6bmMmZmtvUqObOJiFXp83HgBrJrLmtSExjp8/G0eAcwPLd6G7CqQbytRtzMzCrS68VG0hsl7dI5DhwDPATMBzp7lE0E5qXx+cBpqVfaYcDTqZntVuAYSbunjgHHALemeRskHZZ6oZ2W25aZmVWgima0PYEbUm/kvsD3I+IWSfcC10maBDwGnJyWXwCMA9qB54EzACJivaQZwL1puQsiYn0a/wQwC9gJuDkNZmZWkV4vNhHxCHBQjfg64Oga8QDO6mZbM4GZNeKLgAO2OlkzM9smmqnrs5mZtSgXGzMzK52LjZmZlc7FxszMSudiY2ZmpXOxMTOz0rnYmJlZ6VxszMysdC42ZmZWOhcbMzMrnYuNmZmVzsXGzMxK52JjZmalc7ExM7PSudiYmVnpXGzMzKx0LjZmZlY6FxszMyudi42ZmZXOxcbMzErnYmNmZqVzsTEzs9K52JiZWelcbMzMrHQuNmZmVjoXGzMzK52LjZmZlc7FxszMSudiY2ZmpXOxMTOz0rnYmJlZ6VxszMysdC1bbCSNlfR7Se2Spladj5nZ61lLFhtJfYBvAMcB+wGnStqv2qzMzF6/WrLYAIcC7RHxSES8BMwFJlSck5nZ61bfqhMoyTBgRW66A3hX14UkTQYmp8lnJf2+F3JrZDDwRNVJ1NDyeelL22Irf9Hy39c25rx6btvldr62Zu29iyzUqsWm1jcXmwUirgSuLD+d4iQtiogxVefRlfPqGefVM86r55o5t1patRmtAxiem24DVlWUi5nZ616rFpt7gVGSRkrqD5wCzK84JzOz162WbEaLiI2SpgC3An2AmRGxpOK0imqqZr0c59UzzqtnnFfPNXNum1HEZpcyzMzMtqlWbUYzM7Mm4mJjZmalc7FpIpLOlvSQpCWSPlVhHjMlPS7poVxsoKSFkpalz92bJK+T0/f1iqRKuoF2k9eXJf1O0oOSbpC0W5PkNSPl9ICkn0ga2gx55eb9s6SQNLgZ8pI0XdLK9H09IGlcM+SV4p9Mj+RaIun/9XZePeVi0yQkHQB8jOzpBwcBH5Q0qqJ0ZgFju8SmArdFxCjgtjTd22axeV4PAScBP+/1bF41i83zWggcEBEHAv8DnNvbSVE7ry9HxIERMRq4CfhCr2dVOy8kDQfeDzzW2wkls6iRF3BpRIxOw4Jezglq5CXpfWRPRTkwIvYHvlJBXj3iYtM83gbcFRHPR8RG4E7gxCoSiYifA+u7hCcAs9P4bOCEXk2K2nlFxMMRUemTH7rJ6yfp3xHgLrJ7vZohr2dyk2+kxs3OZevmvy+AS4HPUkFOUDevSnWT1yeAiyPixbTM472eWA+52DSPh4AjJA2S9AZgHK+9MbVqe0bEaoD0OaTifLYnZwI3V51EJ0kXSloBfJhqzmw2I2k8sDIiflt1LjVMSU2PM6toPu7GXwPvkXS3pDslHVJ1Qo242DSJiHgY+BJZ88stwG+BjXVXsqYn6fNk/47XVp1Lp4j4fEQMJ8tpStX5pD+uPk+TFL4urgDeAowGVgOXVJvOX/QFdgcOA/4FuE7SVj3grGwuNk0kIq6OiIMj4giy0+ZlVeeUs0bSXgDps+lP26smaSLwQeDD0Zw3tH0f+N9VJ0H2Yz4S+K2k5WRNjvdL+qtKswIiYk1EbIqIV4CryK6pNoMO4EeRuQd4hezBnE3LxaaJSBqSPt9MdtF7TrUZvcZ8YGIanwjMqzCXpidpLHAOMD4inq86n05dOp2MB35XVS6dImJxRAyJiBERMYLsh/TgiPhTxal1/mHV6USy5u5mcCNwFICkvwb607xPp85EhIcmGYD/BpaSNaEdXWEec8iaDF4m+x9/EjCIrBfasvQ5sEnyOjGNvwisAW5tkrzayV5z8UAavtUkef2Q7AfzQeDHwLBmyKvL/OXA4GbIC/gusDh9X/OBvZokr/7A99K/5f3AUb2dV08HP67GzMxK52Y0MzMrnYuNmZmVzsXGzMxK52JjZmalc7ExM7PSudiYmVnpXGzMzKx0/x8uxyKi1CV0bgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(10,first_len,3, label=\"1\")\n",
    "plt.bar(15,second_len,3, label=\"0\")\n",
    "plt.legend()\n",
    "plt.ylabel('Number of examples')\n",
    "plt.title('Proportion of examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    '''a function for removing punctuation'''\n",
    "    import string\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['question1'] = train_data['question1'].apply(remove_punctuation)\n",
    "train_data['question2'] = train_data['question2'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor KohiNoor Diamond</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely How can I solve it</td>\n",
       "      <td>Find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>Which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology I am a Capricorn Sun Cap moon and ca...</td>\n",
       "      <td>Im a triple Capricorn Sun Moon and ascendant i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist</td>\n",
       "      <td>What should I do to be a great geologist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し</td>\n",
       "      <td>When do you use  instead of and</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola company Can I hack my Charter Motorol...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4     What is the story of Kohinoor KohiNoor Diamond   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8   Why am I mentally very lonely How can I solve it   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar salt ...   \n",
       "5   5    11    12  Astrology I am a Capricorn Sun Cap moon and ca...   \n",
       "6   6    13    14                                 Should I buy tiago   \n",
       "7   7    15    16                      How can I be a good geologist   \n",
       "8   8    17    18                     When do you use シ instead of し   \n",
       "9   9    19    20  Motorola company Can I hack my Charter Motorol...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when math2324math is divide...             0  \n",
       "4             Which fish would survive in salt water             0  \n",
       "5  Im a triple Capricorn Sun Moon and ascendant i...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7           What should I do to be a great geologist             1  \n",
       "8                    When do you use  instead of and             0  \n",
       "9   How do I hack Motorola DCX3400 for free internet             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(text):\n",
    "    '''a function for removing the stopword'''\n",
    "    # removing the stop words and lowercasing the selected words\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    # joining the list of words with space separator\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['question1'] = train_data['question1'].apply(stopwords)\n",
    "train_data['question2'] = train_data['question2'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>internet speed increased hacking dns</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder math2324math divided 2423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2          step step guide invest share market india   \n",
       "1   1     3     4                    story kohinoor kohinoor diamond   \n",
       "2   2     5     6       increase speed internet connection using vpn   \n",
       "3   3     7     8                              mentally lonely solve   \n",
       "4   4     9    10  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0                step step guide invest share market             0  \n",
       "1  would happen indian government stole kohinoor ...             0  \n",
       "2               internet speed increased hacking dns             0  \n",
       "3           find remainder math2324math divided 2423             0  \n",
       "4                      fish would survive salt water             0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stemming(text):    \n",
    "    '''a function which stems each word in the given text'''\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return \" \".join(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>step step guid invest share market india</td>\n",
       "      <td>step step guid invest share market</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>stori kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian govern stole kohinoor kohi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>increas speed internet connect use vpn</td>\n",
       "      <td>internet speed increas hack dns</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>mental lone solv</td>\n",
       "      <td>find remaind math2324math divid 2423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>one dissolv water quik sugar salt methan carbo...</td>\n",
       "      <td>fish would surviv salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>astrolog capricorn sun cap moon cap risingwhat...</td>\n",
       "      <td>im tripl capricorn sun moon ascend capricorn say</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>buy tiago</td>\n",
       "      <td>keep childern activ far phone video game</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>good geologist</td>\n",
       "      <td>great geologist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>use シ instead し</td>\n",
       "      <td>use instead</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>motorola compani hack charter motorolla dcx3400</td>\n",
       "      <td>hack motorola dcx3400 free internet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2           step step guid invest share market india   \n",
       "1   1     3     4                    stori kohinoor kohinoor diamond   \n",
       "2   2     5     6             increas speed internet connect use vpn   \n",
       "3   3     7     8                                   mental lone solv   \n",
       "4   4     9    10  one dissolv water quik sugar salt methan carbo...   \n",
       "5   5    11    12  astrolog capricorn sun cap moon cap risingwhat...   \n",
       "6   6    13    14                                          buy tiago   \n",
       "7   7    15    16                                     good geologist   \n",
       "8   8    17    18                                    use シ instead し   \n",
       "9   9    19    20    motorola compani hack charter motorolla dcx3400   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0                 step step guid invest share market             0  \n",
       "1  would happen indian govern stole kohinoor kohi...             0  \n",
       "2                    internet speed increas hack dns             0  \n",
       "3               find remaind math2324math divid 2423             0  \n",
       "4                       fish would surviv salt water             0  \n",
       "5   im tripl capricorn sun moon ascend capricorn say             1  \n",
       "6           keep childern activ far phone video game             0  \n",
       "7                                    great geologist             1  \n",
       "8                                        use instead             0  \n",
       "9                hack motorola dcx3400 free internet             0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['question1'] = train_data['question1'].apply(stemming)\n",
    "train_data['question2'] = train_data['question2'].apply(stemming)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(train_data.is_duplicate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['question1'] = train_data['question1'].apply(lambda x : nltk.word_tokenize(x))\n",
    "train_data['question2'] = train_data['question2'].apply(lambda x : nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((train_data['question1'],train_data['question2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = collections.Counter()\n",
    "for sentance in data:\n",
    "    for word in sentance:\n",
    "        c[word] += 1\n",
    "\n",
    "\n",
    "common = c.most_common(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('best', 70489),\n",
       " ('get', 44018),\n",
       " ('india', 29386),\n",
       " ('like', 28260),\n",
       " ('use', 27040),\n",
       " ('peopl', 26496),\n",
       " ('good', 25066),\n",
       " ('way', 24978),\n",
       " ('differ', 24091),\n",
       " ('would', 23593),\n",
       " ('make', 23293),\n",
       " ('one', 21448),\n",
       " ('quora', 18175),\n",
       " ('learn', 17945),\n",
       " ('time', 16282),\n",
       " ('life', 15584),\n",
       " ('work', 14633),\n",
       " ('know', 14624),\n",
       " ('money', 14551),\n",
       " ('year', 13998),\n",
       " ('thing', 12990),\n",
       " ('what', 12978),\n",
       " ('think', 12727),\n",
       " ('mean', 12671),\n",
       " ('question', 12654),\n",
       " ('indian', 12512),\n",
       " ('go', 12509),\n",
       " ('new', 12408),\n",
       " ('much', 12367),\n",
       " ('start', 12320)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(common):\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(common)\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  \n",
    "  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "  return dictionary, reverse_dictionary\n",
    "\n",
    "dic, rd = build_dataset(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_encoded = train_data.question1.apply(lambda x: np.array([dic[y] if y in dic.keys() else 0 for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2_encoded = train_data.question2.apply(lambda x: [dic[y] if y in dic.keys() else 0 for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1_encoded.apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_padded = np.array([np.pad(i[:30], pad_width=(0,30 - len(i[:30])), mode='constant') for i in question1_encoded])\n",
    "question2_padded = np.array([np.pad(i[:30], pad_width=(0,30 - len(i[:30])), mode='constant') for i in question2_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 30)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = question1_padded\n",
    "X_train2 = question2_padded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Inputs and Hyperparameters\n",
    "lstm_sizes = [128, 64]\n",
    "vocab_size = 5001 #add one for padding\n",
    "embed_size = 300\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "keep_prob = 0.5\n",
    "batch_size1 = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    \"\"\"\n",
    "    inputs1_ = tf.placeholder(tf.int32, [None, None], name='inputs1')\n",
    "    inputs2_ = tf.placeholder(tf.int32, [None, None], name='inputs2')\n",
    "    labels_ = tf.placeholder(tf.int32, [None,1], name='labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    y_true_cls = tf.argmax(labels_, axis=1)\n",
    "    \n",
    "    return inputs1_, inputs2_, labels_, keep_prob_, y_true_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_layer(inputs1_, inputs2_, vocab_size, embed_size):\n",
    "    \"\"\"\n",
    "    Create the embedding layer\n",
    "    \"\"\"\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_size), 0, 2))\n",
    "    embed1 = tf.nn.embedding_lookup(embedding, inputs1_)\n",
    "    embed2 = tf.nn.embedding_lookup(embedding, inputs2_)\n",
    "    \n",
    "    return embed1, embed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_layers(lstm_sizes, embed1, embed2, keep_prob_, batch_size):\n",
    "   \n",
    "    lstms = [tf.contrib.rnn.BasicLSTMCell(size) for size in lstm_sizes]\n",
    "    # Add dropout to the cell\n",
    "    drops = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_) for lstm in lstms]\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(drops)\n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    lstm_outputs1, final_state = tf.nn.dynamic_rnn(cell, embed1, initial_state=initial_state)\n",
    "    lstm_outputs2, final_state = tf.nn.dynamic_rnn(cell, embed2, initial_state=initial_state)\n",
    "    \n",
    "    lstm_outputs1 = tf.reshape(lstm_outputs1, [batch_size,30,64,1])\n",
    "    lstm_outputs2 = tf.reshape(lstm_outputs2, [batch_size,30,64,1])\n",
    "   \n",
    "    return lstm_outputs1, lstm_outputs2, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input1, input2, num_input_channels, filter_size, num_filters, name):\n",
    "      \n",
    "    # Shape of the filter-weights for the convolution\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights (filters) with the given shape\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "        \n",
    "    # Create new biases, one for each filter\n",
    "    biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "    # TensorFlow operation for convolution\n",
    "    output1 = tf.nn.conv2d(input=input1, filter=weights, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    output2 = tf.nn.conv2d(input=input2, filter=weights, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    \n",
    "    # Add the biases to the results of the convolution.\n",
    "    output1 += biases\n",
    "    output2 += biases\n",
    "        \n",
    "    return output1, output2, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pool_layer(input1, input2, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        \n",
    "        output1 = tf.nn.max_pool(value=input1, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "        output2 = tf.nn.max_pool(value=input2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "        \n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_relu_layer(input1, input2, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        \n",
    "        output1 = tf.nn.relu(input1)\n",
    "        output2 = tf.nn.relu(input2)\n",
    "        \n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input1, input2, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        output1 = tf.matmul(input1, weights) + biases\n",
    "        output2 = tf.matmul(input2, weights) + biases\n",
    "        \n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_result_fc_layer(input, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        output = tf.matmul(input, weights) + biases\n",
    "              \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_2:0\", shape=(256, 16112), dtype=float32)\n",
      "Tensor(\"concat:0\", shape=(256, 32224), dtype=float32)\n",
      "Tensor(\"result/add:0\", shape=(256, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs1_, inputs2_, labels_, keep_prob_, y_true_cls = model_inputs()\n",
    "\n",
    "#Embedding layer\n",
    "embed1, embed2 = build_embedding_layer(inputs1_, inputs2_, vocab_size, embed_size)\n",
    "\n",
    "# LSTM layers\n",
    "lstm_outputs1, lstm_outputs2, final_state = build_lstm_layers(lstm_sizes, embed1, embed2, keep_prob, batch_size)\n",
    "\n",
    "# Convolutional Layer 1\n",
    "conv1_out1, conv1_out2, weights_conv1 = new_conv_layer(input1=lstm_outputs1, input2=lstm_outputs2, num_input_channels=1, filter_size=5, num_filters=6, name =\"conv1\")\n",
    "\n",
    "# Pooling Layer 1\n",
    "pool1_out1, pool1_out2 = new_pool_layer(conv1_out1, conv1_out2, name=\"pool1\")\n",
    "\n",
    "# RelU layer 1\n",
    "relu1_out1, relu1_out2 = new_relu_layer(pool1_out1, pool1_out2, name=\"relu1\")\n",
    "\n",
    "# Convolutional Layer 2\n",
    "conv2_out1, conv2_out2, weights_conv2 = new_conv_layer(input1=relu1_out1, input2=relu1_out2, num_input_channels=6, filter_size=5, num_filters=16, name= \"conv2\")\n",
    "\n",
    "# Pooling Layer 2\n",
    "pool2_out1, pool2_out2 = new_pool_layer(conv2_out1, conv2_out2, name=\"pool2\")\n",
    "\n",
    "# RelU layer 2\n",
    "relu2_out1, relu2_out2 = new_relu_layer(pool2_out1, pool2_out2, name=\"relu2\")\n",
    "\n",
    "# Pooling layer 3\n",
    "pool3_out1, pool3_out2 = new_pool_layer(relu2_out1, relu2_out2, name=\"pool3\")\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = pool3_out1.get_shape()[1:4].num_elements()\n",
    "layer_flat1 = tf.reshape(pool3_out1, [-1, num_features])\n",
    "layer_flat2 = tf.reshape(pool3_out2, [-1, num_features])\n",
    "layer_flat = tf.concat([layer_flat1, layer_flat2], 1)\n",
    "\n",
    "# Fully connected layer\n",
    "result = new_result_fc_layer(input=layer_flat, num_inputs=32224, num_outputs=1, name=\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(result)\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=result, labels=labels_)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "Epoch 1 completed : Time usage 3111 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t1.0\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-581ee8e4077a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Calculate the accuracy on the batch of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Generate summary with the current batch of data and write to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "        \n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        batch_size = batch_size1\n",
    "        start_time = time.time()\n",
    "        train_accuracy = 0\n",
    "        \n",
    "        for batch in range(0, int(len(X_train1)/batch_size)):\n",
    "            if batch % 10 == 0:\n",
    "                print(batch)\n",
    "            # Get a batch\n",
    "            x_batch1, x_batch2, y_true_batch = X_train1[batch*batch_size:(batch+1)*batch_size], X_train2[batch*batch_size:(batch+1)*batch_size], y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_true_batch = np.reshape(np.array(y_true_batch),[batch_size,1])\n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {inputs1_: x_batch1, inputs2_: x_batch2, labels_: y_true_batch, keep_prob_: keep_prob}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            writer.add_summary(summ, epoch*int(len(data)/batch_size) + batch)\n",
    "        \n",
    "          \n",
    "        train_accuracy /= int(len(X_train1)/batch_size)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
